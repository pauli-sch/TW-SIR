{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "from sklearn import  linear_model\n",
    "from sklearn.preprocessing import  PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def readDeathData(country):\n",
    "    \"\"\"\n",
    "    Liest Daten ueber die Anzahl der Tote aus\n",
    "    :param country: Land\n",
    "    :return: ausgelesene Daten\n",
    "    \"\"\"\n",
    "    death_data = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "    data = death_data[(death_data['Country/Region'] == country)].iloc[:,4:]\n",
    "    return data.sum()\n",
    "\n",
    "def readConfirmedData(country):\n",
    "    \"\"\"\n",
    "    liest die Daten ueber die Anzahl der Infizierten ein\n",
    "    :param country: Land\n",
    "    :return: ausgelesene Daten\n",
    "    \"\"\"\n",
    "    recover_data = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "    data = recover_data[(recover_data['Country/Region'] == country)].iloc[:,4:]\n",
    "    return data.sum()\n",
    "\n",
    "def readRecoveredData(country):\n",
    "    \"\"\"\n",
    "    liest die Daten ueber die Anzahl der Genesenen ein\n",
    "    :param country: Land\n",
    "    :return: ausgelesene Daten\n",
    "    \"\"\"\n",
    "    recover_data = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n",
    "    data = recover_data[(recover_data['Country/Region'] == country)].iloc[:,4:]\n",
    "    return data.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Populationsstand verschiedener Laender\n",
    "popu_dict = {'Germany':82927922, 'Italy':60482200}\n",
    "\n",
    "def load_IR(name, N, t,T=None):\n",
    "    \"\"\"\n",
    "    Laedt die Daten der Faelle, Genesenen und Toten\n",
    "    :param name: Das zu betrachtende Land\n",
    "    :param N: Gesamtpopulation\n",
    "    :param t: Startzeitpunkt\n",
    "    :param T: Endzeitpunkt (optional)\n",
    "    :return: Aktive Infizierte, Genesen, Tote, gesamte Faelle\n",
    "    \"\"\"\n",
    "    #T=163\n",
    "\n",
    "    R = readRecoveredData(name)\n",
    "    D = readDeathData(name)\n",
    "    C = readConfirmedData(name)\n",
    "    R = R.tolist()[t:T]\n",
    "    D = D.tolist()[t:T]\n",
    "    C = C.tolist()[t:T]\n",
    "    R = np.array(R)\n",
    "    D = np.array(D)\n",
    "    C = np.array(C)\n",
    "    I = C - R - D\n",
    "    return I,R,D,C\n",
    "\n",
    "def SSE(I_t, I):\n",
    "    \"\"\"\n",
    "    Summe des quadratischen Fehlers\n",
    "    :param I_t: modellierte Infizierte\n",
    "    :param I: Infizierte aus Daten\n",
    "    :return: Summe des quadratischen Fehlers\n",
    "    \"\"\"\n",
    "    sse = (I_t[:len(I)] - I)**2\n",
    "    return sse.sum()\n",
    "\n",
    "def RungeKutta(beta, gamma, N, S_0, I_0, R_0, t):\n",
    "    \"\"\"\n",
    "    Runge-Kutta-Verfahren zum loesen des SIR-Modells\n",
    "    :param beta: Kontaktrate\n",
    "    :param gamma: Genseungsrate\n",
    "    :param N: Gesamtpopulation\n",
    "    :param S_0: Anfangswert des Anfaelligen\n",
    "    :param I_0: Anfangswert des Infizierten\n",
    "    :param R_0: Anfangswert der Toten/Genesenen\n",
    "    :param t: Startzeitpunkt\n",
    "    :return: geloestes SIR-Modell ab t mit S_t, I_t, R_t\n",
    "    \"\"\"\n",
    "    days = 200\n",
    "    X = np.arange(t, days)\n",
    "    I_t = np.zeros(days)\n",
    "    S_t = np.zeros(days)\n",
    "    R_t = np.zeros(days)\n",
    "    I_t[0] = I_0\n",
    "    S_t[0] = S_0\n",
    "    R_t[0] = R_0\n",
    "    h = 1\n",
    "    for i in range(1, days):\n",
    "        k11 = -beta * S_t[i-1] * I_t[i-1] / N\n",
    "        k21 = beta * S_t[i-1] * I_t[i-1] / N - gamma * I_t[i-1]\n",
    "        k31 = gamma * I_t[i-1]\n",
    "\n",
    "        k12 = -beta * (S_t[i-1] + h / 2 * k11) * (I_t[i-1] + h / 2 * k21) / N\n",
    "        k22 = beta * (S_t[i-1] + h / 2 * k11) * (I_t[i-1] + h / 2 * k21) / N - gamma * (I_t[i-1] + h / 2 * k21)\n",
    "        k32 = gamma * (I_t[i-1] + h / 2 * k21)\n",
    "\n",
    "        k13 = -beta * (S_t[i-1] + h / 2 * k12) * (I_t[i-1] + h / 2 * k22) / N\n",
    "        k23 = beta * (S_t[i-1] + h / 2 * k12) * (I_t[i-1] + h / 2 * k22) / N - gamma * (I_t[i-1] + h / 2 * k22)\n",
    "        k33 = gamma * (I_t[i-1] + h / 2 * k22)\n",
    "\n",
    "        k14 = -beta * (S_t[i-1] + h * k13) * (I_t[i-1] + h * k23) / N\n",
    "        k24 = beta * (S_t[i-1] + h * k13) * (I_t[i-1] + h * k23) / N - gamma * (I_t[i-1] + h * k23)\n",
    "        k34 = gamma * (I_t[i-1] + h * k23)\n",
    "\n",
    "        S_t[i] = S_t[i-1] + h / 6 * (k11 + 2 * k12 + 2 * k13 + k14)\n",
    "        I_t[i] = I_t[i-1] + h / 6 * (k21 + 2 * k22 + 2 * k23 + k24)\n",
    "        R_t[i] = R_t[i-1] + h / 6 * (k31 + 2 * k32 + 2 * k33 + k34)\n",
    "    return S_t[t:],I_t[t:],R_t[t:]\n",
    "\n",
    "def create_assist_date(datestart = None,dateend = None):\n",
    "    \"\"\"\n",
    "    Erstellt eine Liste von Daten\n",
    "    :param datestart: Startdatum\n",
    "    :param dateend: Enddatum\n",
    "    :return: Liste von Daten zwischen datestart und dateend\n",
    "    \"\"\"\n",
    "    if datestart is None:\n",
    "        datestart = '2016-01-01'\n",
    "    if dateend is None:\n",
    "        dateend = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    datestart=datetime.datetime.strptime(datestart,'%Y-%m-%d')\n",
    "    dateend=datetime.datetime.strptime(dateend,'%Y-%m-%d')\n",
    "    date_list = [datestart.strftime('%Y-%m-%d')]\n",
    "    while datestart<dateend:\n",
    "        datestart+=datetime.timedelta(days=+1)\n",
    "        date_list.append(datestart.strftime('%Y-%m-%d'))\n",
    "    return date_list\n",
    "\n",
    "def predictPlot(I, I_t, t=None):\n",
    "    \"\"\"\n",
    "    Plot von I und I_t\n",
    "    :param I: gemessenen Infizierten\n",
    "    :param I_t: modellierte oder vorhergesagt Infizierte\n",
    "    :param t: Start ab wann vorhergesagt wird\n",
    "    \"\"\"\n",
    "    #date_X = create_assist_date(\"2020-1-22\", \"2020-10-01\")\n",
    "    x_test  =pd.date_range(start='1/22/2020', end='10/1/2023', freq='D')\n",
    "    X = np.arange(0, len(I_t))\n",
    "    ax  = plt.figure(figsize=(14, 8))\n",
    "    plt.grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    sns.lineplot(x_test[:len(I)], I, label = 'echte Daten')\n",
    "    sns.set_style('whitegrid')\n",
    "    if t is not None:\n",
    "        sns.lineplot(x_test[0:t],I_t[0:t],label=\"Modelliert\")\n",
    "        sns.lineplot(x_test[t:len(I_t)], I_t[t:], label='Vorhersage')\n",
    "    else:\n",
    "        sns.lineplot(x_test[:len(I_t)],I_t,label=\"Modelliert\")\n",
    "    plt.xlabel('Zeit')\n",
    "    plt.ylabel('Anzahl aktiver Infizierten')\n",
    "    plt.title('SIR Modell')\n",
    "\n",
    "def oneDayError(I,I_p):\n",
    "    \"\"\"\n",
    "    Vorhersage Fehler\n",
    "    :param I: gemessene Daten\n",
    "    :param I_p: modellierte oder vorhergesagte Daten\n",
    "    :return: Liste der Fehler\n",
    "    \"\"\"\n",
    "    error = ((I_p[:len(I)] - I)/I)\n",
    "    X = np.arange(0, len(error))\n",
    "    x_test  =pd.date_range(start='1/22/2020', end='10/1/2023', freq='D')\n",
    "    ax  = plt.figure(figsize=(13, 8))\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.lineplot(x_test[:len(error)],error, label=\"Error\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Size of Error')\n",
    "    plt.title('Prediction Error')\n",
    "    plt.savefig('error.png')\n",
    "    return error\n",
    "\n",
    "def read_I_t(I,country, size):\n",
    "    \"\"\"\n",
    "    Liest die bereits modellierten Werte von I_t ein\n",
    "    :param I: gemessene I\n",
    "    :param country: Land\n",
    "    :param size: Groesse des Zeitfenster\n",
    "    :return: Liste der modellierten I\n",
    "    \"\"\"\n",
    "    I_t_list = []\n",
    "    I_t_all = []\n",
    "    I_t_p = list(I[0:size])\n",
    "\n",
    "    for i in range(0, len(I)- size +1 ):\n",
    "        if i == len(I) - size:\n",
    "            j = len(I) - 1\n",
    "        else:\n",
    "            j = i + size - 1\n",
    "        file_name = str(i) + '_'+str(j)+'_It.csv'\n",
    "        a = pd.read_csv('data/'+country+'/'+str(size)+'/'+file_name,engine='python')\n",
    "        I_t = list(a['I_t'])\n",
    "        I_t_list.append(I_t)\n",
    "\n",
    "        if i == len(I) - size:\n",
    "            I_t_all = I_t_all + I_t\n",
    "            I_t_p = I_t_p + I_t[size:]\n",
    "        else:\n",
    "            I_t_all = I_t_all + I_t[:1]\n",
    "            I_t_p.append(I_t[size])\n",
    "    return I_t_p,I_t_all\n",
    "\n",
    "\n",
    "def read_opt(I,country, size):\n",
    "    \"\"\"\n",
    "    liest die optimalen Parameter\n",
    "    :param I: gemessene I\n",
    "    :param country: Land\n",
    "    :param size: Groesse des Zeitfenster\n",
    "    :return: Liste von optimalen beta und gamma\n",
    "    \"\"\"\n",
    "    beta_list = []\n",
    "    gamma_list = []\n",
    "    for i in range(0, len(I)- size+1):\n",
    "        if i == len(I) - size:\n",
    "            j = len(I) - 1\n",
    "        else:\n",
    "            j = i + size-1\n",
    "        file_name = str(i) + '_'+str(j)+'_opt.csv'\n",
    "        a = pd.read_csv('data/'+country+'/'+str(size)+'/'+file_name,engine='python')\n",
    "        #opt = a.iloc[a['sse'].idxmin(),][1:3].tolist()\n",
    "        opt = a.iloc[0,1:3].tolist()\n",
    "        beta_list.append(opt[0])\n",
    "        gamma_list.append(opt[1])\n",
    "    beta_list = np.array(beta_list,dtype=\"float64\")\n",
    "    gamma_list = np.array(gamma_list,dtype=\"float64\")\n",
    "    return beta_list,gamma_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "minMSE = float('inf')\n",
    "opt = 0\n",
    "\n",
    "def paramPredict(datasets_X,datasets_Y):\n",
    "    \"\"\"\n",
    "    Vorhersage mithilfer einer polynomialen Regression\n",
    "    :param datasets_X: Ausgangsgroesse\n",
    "    :param datasets_Y: Zielgroesse\n",
    "    :return: Vorhersage von Y\n",
    "    \"\"\"\n",
    "    #Mit degree kann der Grad des Polynoms fuer die Regression eingestellt werden\n",
    "    poly_reg =PolynomialFeatures(degree=2)\n",
    "    X_ploy =poly_reg.fit_transform(datasets_X)\n",
    "    lin_reg_2=linear_model.LinearRegression()\n",
    "    lin_reg_2.fit(X_ploy,datasets_Y)\n",
    "    y_predict = lin_reg_2.predict(poly_reg.fit_transform(datasets_X))\n",
    "    nextX = np.array(datasets_X[-1][0]+1).reshape([1,1])\n",
    "    nextY = lin_reg_2.predict(poly_reg.fit_transform(nextX))\n",
    "    #nextY ist nur eine Zahl\n",
    "    return nextY\n",
    "\n",
    "def parameterPlot(beta, gamma):\n",
    "    \"\"\"\n",
    "    Berechnet aus beta und gamme die exp. Wachstumsrate und die Basisreproduktionszahl\n",
    "    :param beta: Kontakrate\n",
    "    :param gamma: Genesungsrate\n",
    "    :return: exp. Wachstumsrate und Basisreproduktionszahl\n",
    "    \"\"\"\n",
    "    beta = beta.tolist()\n",
    "    gamma = gamma.tolist()\n",
    "    r =[]\n",
    "    ex = []\n",
    "    for i in range(0, len(beta)-1):\n",
    "        r.append(beta[i]/gamma[i])\n",
    "        ex.append(beta[i]-gamma[i])\n",
    "\n",
    "    return r, ex\n",
    "def predictParameter(data_x, data_y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_x[:-50], data_y, shuffle=False)\n",
    "    quadratic = PolynomialFeatures(degree=2)\n",
    "    x_train_quad = quadratic.fit_transform(x_train)\n",
    "    x_test_quad = quadratic.transform(x_test)\n",
    "\n",
    "    regressor = linear_model.LinearRegression()\n",
    "    regressor.fit(x_train_quad, y_train)\n",
    "    xx_quad = quadratic.transform(data_x.reshape(data_x.shape[0], 1))\n",
    "    print('r-squared', regressor.score(x_test_quad, y_test))\n",
    "    return regressor.predict(xx_quad)\n",
    "\n",
    "def predictSomething(country, size, t):\n",
    "    I,R,D,C = load_IR(country,popu_dict[country],0)\n",
    "    beta_list,gamma_list = read_opt(I,country, size)\n",
    "    r0,dif = parameterPlot(beta_list[:t],gamma_list[:t])\n",
    "    leng = len(r0)+50\n",
    "    datasets_X = np.arange(0, leng).reshape([leng,1])\n",
    "    dif_new = predictParameter(datasets_X, dif)\n",
    "    r0_new = predictParameter(datasets_X, r0)\n",
    "    plt.figure()\n",
    "    plt.plot(datasets_X[:len(dif)],dif, label=\"Ex(t) aus Modell\", linewidth=0.5)\n",
    "    plt.plot(datasets_X, dif_new, label='Ex(t) predicted')\n",
    "    plt.title('Ex(t)')\n",
    "    plt.grid(True)\n",
    "    plt.figure()\n",
    "    plt.title('R0(t)')\n",
    "    plt.plot(datasets_X[:len(r0)], r0, linewidth=0.5)\n",
    "    plt.plot(datasets_X, r0_new)\n",
    "    plt.grid(True)\n",
    "    gamma =dif_new/(r0_new-1)\n",
    "    beta = r0_new*gamma\n",
    "    I_t_p, I_t_all = read_I_t(I, country, size)\n",
    "    I_p = list(I_t_p)[:t]\n",
    "    for i in range(0,50):\n",
    "        S_t, I_t, R_t = RungeKutta(beta[len(r0)+i], gamma[len(r0)+i], popu_dict[country],\n",
    "                                   popu_dict[country] - I[len(r0)+i] - R[len(r0)+i], I[len(r0)+i], R[len(r0)+i], 0)\n",
    "        I_p.append(I_t[size])\n",
    "\n",
    "    I_p = np.array(I_p)\n",
    "    predictPlot(I, I_p, t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predictTime(country, size, t):\n",
    "    I,R,D,C = load_IR(country,popu_dict[country],0)\n",
    "    beta_list,gamma_list = read_opt(I,country, size)\n",
    "    print(len(beta_list))\n",
    "    r0,dif = parameterPlot(beta_list[:t],gamma_list[:t])\n",
    "    datasets_X = np.arange(0, len(r0)).reshape([len(r0),1])\n",
    "    dif_new = paramPredict(datasets_X[-size:], dif[-size:])\n",
    "    r0_new = paramPredict(datasets_X[-size:], r0[-size:])\n",
    "    gamma = dif_new / (r0_new - 1)\n",
    "    beta = r0_new * gamma\n",
    "    #print(beta, gamma)\n",
    "    I_t_p,I_t_all = read_I_t(I,country,size)\n",
    "    print('Length I_t', len(I_t_p))\n",
    "    S_t,I_t,R_t = RungeKutta(beta, gamma, popu_dict[country], popu_dict[country] - I[t-1] - R[t-1], I[t-1], R[t-1], 0)\n",
    "    I_p = list(I_t_p)[:t]\n",
    "    I_p = I_p + list(I_t)\n",
    "    #I_p.append(I_t)\n",
    "    I_p = np.array(I_p)\n",
    "    predictPlot(I[0:t+80],I_p[0:t+80], t)\n",
    "    dirs = '\\\\data\\\\'\n",
    "    dir_path = os.path.dirname(os.path.abspath('__file__')) + dirs\n",
    "    dir_path = dir_path+country+'\\\\'+'Picture'+'\\\\'\n",
    "    plt.savefig(dir_path + 'future%i.png' %t)\n",
    "\n",
    "    C_p = list(C)\n",
    "    ax  = plt.figure(figsize=(13, 8))\n",
    "    for i in range(len(C), len(I_p)):\n",
    "        a = C_p[i-1] + (C_p[i-1] - C_p[i-2])*0.97\n",
    "        C_p.append(a)\n",
    "\n",
    "    dirs = '\\\\data\\\\'\n",
    "    dir_path = os.path.dirname(os.path.abspath('__file__')) + dirs\n",
    "    dir_path = dir_path+country+'\\\\'\n",
    "    date_X = create_assist_date(\"2020-1-22\", \"2021-10-01\")\n",
    "    data = []\n",
    "    for i in range(0, t+50):\n",
    "        if i < len(I):\n",
    "            data.append((date_X[i], I[i],R[i],D[i],C[i],I_p[i],C_p[i]))\n",
    "        else:\n",
    "            data.append((date_X[i], '', '', '', '', I_p[i],C_p[i]))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns=['date','I','R', 'D', 'C', 'I_p','C_p']\n",
    "    df.to_csv(dir_path +'predictTime.csv')\n",
    "    return I, I_p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def justPredict(size, country, t, r0, dif, datasets_X, I, R,  forecastType, smoothday=None):\n",
    "    # normal: normale Vorhersage\n",
    "    # smooth: geglaettete Basisreproduktionszahl und exp. Wachstumsrate\n",
    "    # allDays: pol. Regression mit allen Tagen\n",
    "    # mix: pol. Regression mit letzten 31 Tagen und geglaettet\n",
    "    test = 37\n",
    "    if forecastType == 'normal':\n",
    "        dif_new = paramPredict(datasets_X[-test:], dif[-test:])\n",
    "        r0_new = paramPredict(datasets_X[-test:], r0[-test:])\n",
    "    elif forecastType == 'smooth15':\n",
    "        r0hat = scipy.signal.savgol_filter(r0, smoothday, 2)\n",
    "        difhat = scipy.signal.savgol_filter(dif, smoothday, 2)\n",
    "        dif_new = paramPredict(datasets_X[-size:], difhat[-size:])\n",
    "        r0_new = paramPredict(datasets_X[-size:], r0hat[-size:])\n",
    "    elif forecastType == 'allDays':\n",
    "        dif_new = paramPredict(datasets_X, dif)\n",
    "        r0_new = paramPredict(datasets_X, r0)\n",
    "    elif forecastType == 'mix':\n",
    "        r0hat = scipy.signal.savgol_filter(r0, 31, 2)\n",
    "        difhat = scipy.signal.savgol_filter(dif, 31, 2)\n",
    "        dif_new = paramPredict(datasets_X[-37:], difhat[-37:])\n",
    "        r0_new = paramPredict(datasets_X[-37:], r0hat[-37:])\n",
    "\n",
    "    gamma = dif_new / (r0_new - 1)\n",
    "    beta = r0_new * gamma\n",
    "    I_t_p,I_t_all = read_I_t(I,country,size)\n",
    "    S_t,I_t,R_t = RungeKutta(beta, gamma, popu_dict[country], popu_dict[country] - I[t-1] - R[t-1], I[t-1], R[t-1], 0)\n",
    "    I_p = list(I_t_p)[:t]\n",
    "    I_p = I_p + list(I_t)\n",
    "    I_p = np.array(I_p)\n",
    "    return I_p\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}